{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n",
      "parts\n"
     ]
    }
   ],
   "source": [
    "Path_to_midi = 'RTML Project Data'\n",
    "notes = []\n",
    "for file in glob.glob(Path_to_midi+'/*/*.mid'):\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    if parts: # file has instrument parts\n",
    "        print(\"parts\")\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes in a flat structure\n",
    "        print(\"Flat\")\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab=len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequence_length = 100\n",
    "\n",
    "# get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "n_patterns = len(network_input)\n",
    "    \n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# normalize input\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "# network_output=np.eye(n_vocab, dtype='uint8')[network_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, n_vocab):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm=nn.LSTM(1,hidden_size,dropout = 0.3,batch_first=False).float()\n",
    "        self.lstm2=nn.LSTM(hidden_size,hidden_size, dropout = 0.3,batch_first=False).float()\n",
    "        self.lstm3=nn.LSTM(hidden_size,hidden_size).float()\n",
    "        self.batch_normalization = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        self.batch_normalization2 = nn.BatchNorm1d(num_features=256)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(hidden_size,256)\n",
    "        self.out_layer = nn.Linear(256,n_vocab)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2output = nn.Linear(hidden_size, n_vocab)\n",
    "        \n",
    "    def init_hidden(self,sequence_length,hidden_size):\n",
    "        return (torch.randn(1,sequence_length, hidden_size), torch.randn(1,sequence_length, hidden_size),\n",
    "                torch.randn(1,sequence_length, hidden_size), torch.randn(1,sequence_length, hidden_size),\n",
    "                torch.randn(1,sequence_length, hidden_size), torch.randn(1,sequence_length, hidden_size))\n",
    "\n",
    "    def forward(self, input_sequence,hidden):\n",
    "#         print(hidden[0].shape)\n",
    "#         print(hidden[1].type())\n",
    "#         print(input_sequence.shape)\n",
    "        output,(h1,c1) = self.lstm(input_sequence,(hidden[0],hidden[1]))\n",
    "        output,(h2,c2) = self.lstm2(output,(hidden[2],hidden[3]))\n",
    "        output,(h3,c3) = self.lstm3(output,(hidden[4],hidden[5]))\n",
    "#         print(output.shape)\n",
    "        output[0][:-1].detach()\n",
    "        output = output.squeeze()[-1]\n",
    "#         output.requires_grad = True\n",
    "#         output = self.batch_normalization(output.squeeze())\n",
    "        output = self.drop_out(output)\n",
    "        output = self.linear(h3[0][-1])\n",
    "        output = self.relu(output)\n",
    "#         output = self.batch_normalization2(output.squeeze())\n",
    "        output = self.drop_out(output)\n",
    "        output = self.out_layer(output)\n",
    "#         print(output.shape)\n",
    "        output = self.softmax(output)\n",
    "        output = output.unsqueeze(0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(512,100,n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i = torch.from_numpy(network_input).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i = lstm_model.init_hidden(100,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(345)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model(n_i[0].unsqueeze(0),h_i).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteron = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(lstm_model.parameters(),lr=0.01)\n",
    "lstm_model.train()\n",
    "for i in range(2,20):\n",
    "#     lstm_model.zero_grad()\n",
    "    a=lstm_model(input_sequence = n_i[i].unsqueeze(0),hidden=h_i)\n",
    "    print(\"Predicted output is: \",a.argmax().item())\n",
    "    print(\"Actual output is: \",network_output[i])\n",
    "    loss = criteron(a,torch.tensor([network_output[i]]))\n",
    "    print(\"Loss is: \",loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMC(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, n_vocab):\n",
    "        super(LSTMC, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm=nn.LSTMCell(1,hidden_size).float()\n",
    "        self.lstm2=nn.LSTMCell(hidden_size,hidden_size).float()\n",
    "        self.lstm3=nn.LSTMCell(hidden_size,hidden_size).float()\n",
    "        self.batch_normalization = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        self.batch_normalization2 = nn.BatchNorm1d(num_features=256)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(hidden_size,256)\n",
    "        self.out_layer = nn.Linear(256,n_vocab)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        \n",
    "    def init_hidden(self,sequence_length,hidden_size,batch_size):\n",
    "        return (torch.randn(batch_size, hidden_size,device=device), torch.randn(batch_size, hidden_size,device=device),\n",
    "                torch.randn(batch_size, hidden_size,device=device), torch.randn(batch_size, hidden_size,device=device),\n",
    "                torch.randn(batch_size, hidden_size,device=device), torch.randn(batch_size, hidden_size,device=device))\n",
    "\n",
    "    def forward(self, input_sequence,hidden):\n",
    "#         print(hidden[0].shape)\n",
    "#         print(hidden[1].type())\n",
    "#         print(input_sequence.shape)\n",
    "        h1,c1 = self.lstm(input_sequence,(hidden[0],hidden[1]))\n",
    "        h1 = self.drop_out(h1)\n",
    "        h2,c2 = self.lstm2(h1,(hidden[2],hidden[3]))\n",
    "        h2 = self.drop_out(h2)\n",
    "        h3,c3 = self.lstm3(h2,(hidden[4],hidden[5]))\n",
    "#         print(h3.shape)\n",
    "        if(h1.size(0)>1):\n",
    "            output = self.batch_normalization(h3)\n",
    "        else:\n",
    "            output = h3\n",
    "        output = self.drop_out(output)\n",
    "        output = self.linear(output)\n",
    "        output = self.relu(output)\n",
    "        if(output.size(0)>1):\n",
    "            output = self.batch_normalization2(output)\n",
    "        output = self.drop_out(output)\n",
    "        output = self.out_layer(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "n_i = torch.tensor(network_input,device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMC(\n",
       "  (lstm): LSTMCell(1, 512)\n",
       "  (lstm2): LSTMCell(512, 512)\n",
       "  (lstm3): LSTMCell(512, 512)\n",
       "  (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_normalization2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop_out): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (out_layer): Linear(in_features=256, out_features=82, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_cell_model = LSTMC(512,100,n_vocab)\n",
    "lstm_cell_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "criteron = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(lstm_cell_model.parameters(),lr=0.01)\n",
    "\n",
    "def train(batch_size,epochs):\n",
    "    losses=[]\n",
    "    lstm_cell_model.train()\n",
    "    h_i = lstm_cell_model.init_hidden(100,512,batch_size=batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        l=0\n",
    "        for i in range(len(network_output)//batch_size):\n",
    "            lstm_cell_model.zero_grad()    \n",
    "#             s = n_i[i*batch_size:(i+1)*batch_size]\n",
    "            for k in range(sequence_length):\n",
    "                a=lstm_cell_model(input_sequence = n_i[i*batch_size:(i+1)*batch_size,k,0:],hidden=h_i)\n",
    "        #         print(\"Predicted output is: \",a.argmax(dim=1))\n",
    "        #         print(\"Actual output is: \",network_output[i])\n",
    "            loss = criteron(a,torch.tensor(network_output[i*batch_size:(i+1)*batch_size],device=device))\n",
    "#             print(\"Loss is: \",loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l+=loss.item()\n",
    "            \n",
    "        losses.append(loss//(len(network_output)//batch_size))\n",
    "        plt.clf()\n",
    "        plt.plot(losses, 'b-')\n",
    "        plt.xlabel('Epoch (%d)' % epoch)\n",
    "        plt.ylabel('Loss')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING IS TILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now creating the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchnames = sorted(set(item for item in notes))\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "\n",
    "h_1 = lstm_cell_model.init_hidden(100,512,1)\n",
    "h_i = [i.to(device) for i in h_1]\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern)))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    \n",
    "    for i in range(sequence_length):\n",
    "        prediction = lstm_cell_model(torch.tensor(prediction_input[:,i:i+1]).float().to(device),h_i)\n",
    "\n",
    "    index = np.argmax(prediction[-1].cpu().detach())\n",
    "    result = int_to_note[index.item()]\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    pattern=np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_output.mid'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from music21 import stream\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Violin()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Violin()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.insert(instrument.Violin())\n",
    "\n",
    "midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Till Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=lstm_cell_model(input_sequence = s[:,k,0:],hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([452, 450, 428, 510, 165])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[199, 101, 445, 229, 292]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_i[0:1,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[241]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i = lstm_cell_model.init_hidden(100,512,2)\n",
    "a=lstm_cell_model(input_sequence = n_i[1:3,1],hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([510, 450])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM SIMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_simple(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, n_vocab):\n",
    "        super(LSTM_simple, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=3, batch_first=True,dropout = 0.3).float()        \n",
    "#         self.lstm=nn.LSTM(1,hidden_size,dropout = 0.3,batch_first=False).float()\n",
    "#         self.lstm2=nn.LSTM(hidden_size,hidden_size, dropout = 0.3,batch_first=False).float()\n",
    "#         self.lstm3=nn.LSTM(hidden_size,hidden_size).float()\n",
    "        self.batch_normalization = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        self.batch_normalization2 = nn.BatchNorm1d(num_features=256)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(hidden_size,256)\n",
    "        self.out_layer = nn.Linear(256,n_vocab)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "#         self.tanh = nn.Tanh()\n",
    "        \n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2output = nn.Linear(hidden_size, n_vocab)\n",
    "        \n",
    "    def init_hidden(self,sequence_length,hidden_size):\n",
    "        return (torch.randn(3,1, hidden_size), torch.randn(3,1, hidden_size),\n",
    "                torch.randn(1,1, hidden_size,dtype=torch.double), torch.randn(1,1, hidden_size,dtype=torch.double),\n",
    "                torch.randn(1,1, hidden_size,dtype=torch.double), torch.randn(1,1, hidden_size,dtype=torch.double))\n",
    "\n",
    "    def forward(self, input_sequence,hidden):\n",
    "#         print(hidden[0].shape)\n",
    "#         print(hidden[1].type())\n",
    "#         print(input_sequence.shape)\n",
    "        output,(h1,c1) = self.lstm(input_sequence,(hidden[0],hidden[1]))\n",
    "#         output,(h2,c2) = self.lstm2(output,(hidden[2],hidden[3]))\n",
    "#         output,(h3,c3) = self.lstm3(output,(hidden[4],hidden[5]))\n",
    "#         print(output.squeeze().shape)\n",
    "#         print(h1[-1].shape)\n",
    "#         print(self.tanh(h1[2:3]))\n",
    "#         output = h1[-1]\n",
    "        output = self.batch_normalization(output.squeeze())\n",
    "        output = self.drop_out(output)\n",
    "        output = self.linear(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.batch_normalization2(output.squeeze())\n",
    "        output = self.drop_out(output)\n",
    "        output = self.out_layer(output)\n",
    "#         print(self.softmax(output[-1]))\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_simple(512,100,n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i = model.init_hidden(100,512)\n",
    "a=model(input_sequence = n_i[0].unsqueeze(0).float(),hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 519])"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519,)"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor [1, 2], src [1, 519] and index [1, 2] to have the same size apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-942-e62ba4f2f497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# gather(1,acts.unsqueeze(1).to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m102\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor [1, 2], src [1, 519] and index [1, 2] to have the same size apart from dimension 0"
     ]
    }
   ],
   "source": [
    "# gather(1,acts.unsqueeze(1).to(device))\n",
    "a.gather(0,torch.tensor([99,102]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 99, 102]])"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([99,102]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 519])"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteron = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(),lr=0.0001)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criteron(a[-1].unsqueeze(0),torch.tensor([network_output[0].argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2519, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([519])"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(network_output[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(241)"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(network_output[0]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output[0].argmax().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model(input_sequence = n_i[0].unsqueeze(0).float(),hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(241)"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=model(input_sequence = n_i[0].unsqueeze(0).float(),hidden=h_i)\n",
    "a[-1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criteron(a[-1].unsqueeze(0),torch.tensor([481]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2517, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criteron(a[-1].unsqueeze(0),torch.tensor([network_output[0].argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 519])"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output is:  404\n",
      "Actual output is:  241\n",
      "Loss is:  6.252182960510254\n",
      "Predicted output is:  268\n",
      "Actual output is:  451\n",
      "Loss is:  6.248105049133301\n",
      "Predicted output is:  332\n",
      "Actual output is:  418\n",
      "Loss is:  6.251610279083252\n",
      "Predicted output is:  2056\n",
      "Actual output is:  127\n",
      "Loss is:  6.252231597900391\n",
      "Predicted output is:  653\n",
      "Actual output is:  378\n",
      "Loss is:  6.251732349395752\n",
      "Predicted output is:  194\n",
      "Actual output is:  132\n",
      "Loss is:  6.252285957336426\n",
      "Predicted output is:  191\n",
      "Actual output is:  378\n",
      "Loss is:  6.251818656921387\n",
      "Predicted output is:  1229\n",
      "Actual output is:  132\n",
      "Loss is:  6.251744747161865\n",
      "Predicted output is:  170\n",
      "Actual output is:  241\n",
      "Loss is:  6.250189781188965\n",
      "Predicted output is:  170\n",
      "Actual output is:  208\n",
      "Loss is:  6.252152919769287\n",
      "Predicted output is:  433\n",
      "Actual output is:  451\n",
      "Loss is:  6.248319625854492\n",
      "Predicted output is:  332\n",
      "Actual output is:  127\n",
      "Loss is:  6.249650955200195\n",
      "Predicted output is:  170\n",
      "Actual output is:  396\n",
      "Loss is:  6.251107215881348\n",
      "Predicted output is:  1075\n",
      "Actual output is:  428\n",
      "Loss is:  6.251987457275391\n",
      "Predicted output is:  2756\n",
      "Actual output is:  460\n",
      "Loss is:  6.251481056213379\n",
      "Predicted output is:  332\n",
      "Actual output is:  418\n",
      "Loss is:  6.251711368560791\n",
      "Predicted output is:  1032\n",
      "Actual output is:  460\n",
      "Loss is:  6.250821590423584\n",
      "Predicted output is:  268\n",
      "Actual output is:  428\n",
      "Loss is:  6.2522149085998535\n",
      "Predicted output is:  1316\n",
      "Actual output is:  418\n",
      "Loss is:  6.247895240783691\n",
      "Predicted output is:  797\n",
      "Actual output is:  207\n",
      "Loss is:  6.253000259399414\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(20):\n",
    "    model.zero_grad()\n",
    "    a=model(input_sequence = n_i[i].unsqueeze(0).float(),hidden=h_i)\n",
    "    print(\"Predicted output is: \",a.argmax().item())\n",
    "    print(\"Actual output is: \",network_output[i].argmax())\n",
    "    loss = criteron(a[-2:-1],torch.tensor([network_output[i].argmax()]))\n",
    "    print(\"Loss is: \",loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.252744674682617\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.255208969116211\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.250744342803955\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.25487756729126\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.255208969116211\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.2551679611206055\n",
      "Predicted output is:  451\n",
      "Actual output is:  502\n",
      "Loss is:  6.255159854888916\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.2550368309021\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.254593372344971\n",
      "Predicted output is:  127\n",
      "Actual output is:  502\n",
      "Loss is:  6.255098342895508\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.254260063171387\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.25430965423584\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.254878044128418\n",
      "Predicted output is:  486\n",
      "Actual output is:  502\n",
      "Loss is:  6.247810363769531\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.2550859451293945\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.247452735900879\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.2527313232421875\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.250607490539551\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.255206108093262\n",
      "Predicted output is:  241\n",
      "Actual output is:  502\n",
      "Loss is:  6.254948616027832\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for j in range(20):\n",
    "    i=7777\n",
    "    model.zero_grad()\n",
    "    a=model(input_sequence = n_i[i].unsqueeze(0).float()*n_vocab,hidden=h_i)\n",
    "    print(\"Predicted output is: \",a[-1].argmax().item())\n",
    "    print(\"Actual output is: \",network_output[i].argmax())\n",
    "    loss = criteron(a[-2:-1],torch.tensor([network_output[i].argmax()]))\n",
    "    print(\"Loss is: \",loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(313)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "a=model(input_sequence = n_i[i].unsqueeze(0).float(),hidden=h_i)\n",
    "print(a.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67552, 519)"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model(input_sequence = n_i[i].unsqueeze(0).float(),hidden=h_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0024, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.requires_grad_>"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss = criteron(a,torch.tensor([network_output[0]])).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected dtype Float but got dtype Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-924-52a0569421b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected dtype Float but got dtype Byte"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=model(input_sequence = n_i[7777].unsqueeze(0).float(),hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(241)"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_simple(\n",
       "  (lstm): LSTM(1, 512, num_layers=3, batch_first=True, dropout=0.3)\n",
       "  (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_normalization2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop_out): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (out_layer): Linear(in_features=256, out_features=519, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (hidden2output): Linear(in_features=512, out_features=519, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=model(input_sequence = n_i[11].unsqueeze(0).float(),hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criteron(c[-2:-1],torch.tensor([network_output[11].argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2520, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([451])"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([network_output[10].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([519])"
      ]
     },
     "execution_count": 1019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(258)"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor [1, 1], src [100, 519] and index [1, 1] to have the same size apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1070-e423b423fdbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor [1, 1], src [100, 519] and index [1, 1] to have the same size apart from dimension 0"
     ]
    }
   ],
   "source": [
    "a=torch.gather(c,0,torch.tensor([0]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 519])"
      ]
     },
     "execution_count": 1033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = [[np]*519]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[99]=[0]*519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0]).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.],\n",
       "       [467.],\n",
       "       [466.],\n",
       "       [399.],\n",
       "       [488.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [451.],\n",
       "       [488.],\n",
       "       [481.],\n",
       "       [451.],\n",
       "       [418.],\n",
       "       [176.],\n",
       "       [101.],\n",
       "       [418.],\n",
       "       [335.],\n",
       "       [487.],\n",
       "       [486.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [335.],\n",
       "       [468.],\n",
       "       [437.],\n",
       "       [467.],\n",
       "       [434.],\n",
       "       [435.],\n",
       "       [335.],\n",
       "       [314.],\n",
       "       [229.],\n",
       "       [450.],\n",
       "       [449.],\n",
       "       [514.],\n",
       "       [495.],\n",
       "       [481.],\n",
       "       [494.],\n",
       "       [399.],\n",
       "       [488.],\n",
       "       [445.],\n",
       "       [459.],\n",
       "       [  6.],\n",
       "       [437.],\n",
       "       [176.],\n",
       "       [418.],\n",
       "       [418.],\n",
       "       [451.],\n",
       "       [335.],\n",
       "       [487.],\n",
       "       [486.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [515.],\n",
       "       [451.],\n",
       "       [452.],\n",
       "       [434.],\n",
       "       [435.],\n",
       "       [399.],\n",
       "       [467.],\n",
       "       [335.],\n",
       "       [451.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [208.],\n",
       "       [515.],\n",
       "       [101.],\n",
       "       [192.],\n",
       "       [460.],\n",
       "       [127.],\n",
       "       [292.],\n",
       "       [460.],\n",
       "       [292.],\n",
       "       [481.],\n",
       "       [460.],\n",
       "       [495.],\n",
       "       [481.],\n",
       "       [451.],\n",
       "       [452.],\n",
       "       [488.],\n",
       "       [509.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [452.],\n",
       "       [509.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [509.],\n",
       "       [502.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [488.],\n",
       "       [460.],\n",
       "       [452.],\n",
       "       [207.],\n",
       "       [101.],\n",
       "       [460.],\n",
       "       [488.],\n",
       "       [428.],\n",
       "       [378.],\n",
       "       [132.],\n",
       "       [378.],\n",
       "       [132.]])"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input[0]*n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[467.],\n",
       "       [466.],\n",
       "       [399.],\n",
       "       [488.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [451.],\n",
       "       [488.],\n",
       "       [481.],\n",
       "       [451.],\n",
       "       [418.],\n",
       "       [176.],\n",
       "       [101.],\n",
       "       [418.],\n",
       "       [335.],\n",
       "       [487.],\n",
       "       [486.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [335.],\n",
       "       [468.],\n",
       "       [437.],\n",
       "       [467.],\n",
       "       [434.],\n",
       "       [435.],\n",
       "       [335.],\n",
       "       [314.],\n",
       "       [229.],\n",
       "       [450.],\n",
       "       [449.],\n",
       "       [514.],\n",
       "       [495.],\n",
       "       [481.],\n",
       "       [494.],\n",
       "       [399.],\n",
       "       [488.],\n",
       "       [445.],\n",
       "       [459.],\n",
       "       [  6.],\n",
       "       [437.],\n",
       "       [176.],\n",
       "       [418.],\n",
       "       [418.],\n",
       "       [451.],\n",
       "       [335.],\n",
       "       [487.],\n",
       "       [486.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [515.],\n",
       "       [451.],\n",
       "       [452.],\n",
       "       [434.],\n",
       "       [435.],\n",
       "       [399.],\n",
       "       [467.],\n",
       "       [335.],\n",
       "       [451.],\n",
       "       [314.],\n",
       "       [436.],\n",
       "       [208.],\n",
       "       [515.],\n",
       "       [101.],\n",
       "       [192.],\n",
       "       [460.],\n",
       "       [127.],\n",
       "       [292.],\n",
       "       [460.],\n",
       "       [292.],\n",
       "       [481.],\n",
       "       [460.],\n",
       "       [495.],\n",
       "       [481.],\n",
       "       [451.],\n",
       "       [452.],\n",
       "       [488.],\n",
       "       [509.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [452.],\n",
       "       [509.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [509.],\n",
       "       [502.],\n",
       "       [495.],\n",
       "       [437.],\n",
       "       [488.],\n",
       "       [460.],\n",
       "       [452.],\n",
       "       [207.],\n",
       "       [101.],\n",
       "       [460.],\n",
       "       [488.],\n",
       "       [428.],\n",
       "       [378.],\n",
       "       [132.],\n",
       "       [378.],\n",
       "       [132.],\n",
       "       [241.]])"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input[1]*n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM(512,100,n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "h_i = lstm_model.init_hidden(100,512)\n",
    "a=lstm_model(input_sequence = n_i[i].unsqueeze(0).float(),hidden=h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 519])"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  324\n",
      "Actual output is:  502\n",
      "Loss is:  6.25221586227417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  195\n",
      "Actual output is:  502\n",
      "Loss is:  6.2497758865356445\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  385\n",
      "Actual output is:  502\n",
      "Loss is:  6.2518157958984375\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  273\n",
      "Actual output is:  502\n",
      "Loss is:  6.25088357925415\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  461\n",
      "Actual output is:  502\n",
      "Loss is:  6.253246784210205\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  455\n",
      "Actual output is:  502\n",
      "Loss is:  6.2498908042907715\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  455\n",
      "Actual output is:  502\n",
      "Loss is:  6.249485492706299\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  387\n",
      "Actual output is:  502\n",
      "Loss is:  6.252710819244385\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  188\n",
      "Actual output is:  502\n",
      "Loss is:  6.252235412597656\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  63\n",
      "Actual output is:  502\n",
      "Loss is:  6.253164768218994\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  282\n",
      "Actual output is:  502\n",
      "Loss is:  6.249337673187256\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  102\n",
      "Actual output is:  502\n",
      "Loss is:  6.2467570304870605\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  366\n",
      "Actual output is:  502\n",
      "Loss is:  6.252193450927734\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  367\n",
      "Actual output is:  502\n",
      "Loss is:  6.2513885498046875\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  109\n",
      "Actual output is:  502\n",
      "Loss is:  6.252898693084717\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  493\n",
      "Actual output is:  502\n",
      "Loss is:  6.252996921539307\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  19\n",
      "Actual output is:  502\n",
      "Loss is:  6.252462387084961\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  339\n",
      "Actual output is:  502\n",
      "Loss is:  6.251391887664795\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  339\n",
      "Actual output is:  502\n",
      "Loss is:  6.252930641174316\n",
      "torch.Size([1, 100, 512])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([100, 512])\n",
      "Predicted output is:  325\n",
      "Actual output is:  502\n",
      "Loss is:  6.250540733337402\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train()\n",
    "for j in range(20):\n",
    "    i=7777\n",
    "    a=lstm_model(input_sequence = n_i[i].unsqueeze(0).float()*n_vocab,hidden=h_i)\n",
    "    print(\"Predicted output is: \",a[-1].argmax().item())\n",
    "    print(\"Actual output is: \",network_output[i].argmax())\n",
    "    loss = criteron(a[-2:-1],torch.tensor([network_output[i].argmax()]))\n",
    "    print(\"Loss is: \",loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchnames = sorted(set(item for item in notes))\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "\n",
    "h_1 = model.init_hidden(100,512)\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "    prediction = model(torch.tensor(prediction_input).float(),h_1)\n",
    "\n",
    "    index = np.argmax(prediction[-1].detach())\n",
    "    result = int_to_note[index.item()]\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    pattern=np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.4.7.10',\n",
       " '4.8.11',\n",
       " '2.5.8.10',\n",
       " '5.8.9',\n",
       " '2.3.6',\n",
       " '4.8.11',\n",
       " '7.9.11.1.3.4',\n",
       " '11.3',\n",
       " '10.1',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'B3',\n",
       " '5.10',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '1.7',\n",
       " '3.7.10',\n",
       " '4.8.11',\n",
       " '5.6',\n",
       " '10.0.3',\n",
       " '7.8.0',\n",
       " '8.9.1.2',\n",
       " '4.8.11',\n",
       " 'F2',\n",
       " 'E-4',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '7.9.11.1.3.4',\n",
       " '4.8.11',\n",
       " '0.3.6.8',\n",
       " '4.8.11',\n",
       " '0.1.6',\n",
       " '10.0.3',\n",
       " '11.4',\n",
       " 'D3',\n",
       " '3.6.7',\n",
       " '10.1.3',\n",
       " '10.0.3',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '3.6.8',\n",
       " '6.9.10.1',\n",
       " '4.8.11',\n",
       " 'A0',\n",
       " 'B3',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '10.11.4',\n",
       " 'C2',\n",
       " 'E5',\n",
       " '3.5.9',\n",
       " 'E5',\n",
       " '3.5.10',\n",
       " '3.4.5',\n",
       " '4.8.11',\n",
       " '11.2.4.7',\n",
       " '4.8.11',\n",
       " '2.5.6.9',\n",
       " 'F#4',\n",
       " '3.5.6',\n",
       " '4.8.11',\n",
       " '9.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '10.2.5',\n",
       " '7.9.0.2',\n",
       " '9.1.3',\n",
       " '3.7',\n",
       " '4.8.11',\n",
       " '7.9.11.1.3.4',\n",
       " '4.5.10',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '0.3.6.8',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '9.11',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '5.6.10.1',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '7.11.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '9.11.3.4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.7.8',\n",
       " '3.5.9',\n",
       " '5.6',\n",
       " '8.11',\n",
       " '8.11',\n",
       " 'B3',\n",
       " '4.8.11',\n",
       " '2.5.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.5.6.9',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '3.6.7',\n",
       " '4.8.11',\n",
       " '5.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.3',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '9.11.0.4',\n",
       " '4.8.11',\n",
       " '11.4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'C#5',\n",
       " '4.5.7.9',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '9.11.0.4',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " 'B3',\n",
       " '11.3',\n",
       " '0.4',\n",
       " '0.2.6',\n",
       " '5.7.10.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '1.3.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.7.9',\n",
       " '2.5.6.9',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " '11.1.2.5',\n",
       " '4.8.11',\n",
       " '6.8.9',\n",
       " '4.8.11',\n",
       " '11',\n",
       " '10.11.2',\n",
       " '1.4.7.9',\n",
       " '1.2',\n",
       " '7.9.10.1',\n",
       " '4.8.11',\n",
       " '10.1.4.6',\n",
       " '11.0.3',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.10.11.0',\n",
       " '4.8.11',\n",
       " '7.11.0.2',\n",
       " '10.11.4',\n",
       " 'E5',\n",
       " '5.6.7.9.1',\n",
       " 'F4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '3.7.11',\n",
       " '4.8.11',\n",
       " '1.3.8',\n",
       " '1.3.5',\n",
       " '11.1.2.5',\n",
       " 'C#5',\n",
       " '7.8',\n",
       " '4.8.11',\n",
       " '6.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.9.11.1',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '1.2.4.7.9',\n",
       " '4.8.11',\n",
       " '9.11',\n",
       " '4.5.7.9',\n",
       " 'E5',\n",
       " 'B-3',\n",
       " '4.7.8',\n",
       " '4.8.11',\n",
       " '7.9',\n",
       " '3.6.7',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '7.10.1.3',\n",
       " '1.3.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.3.6.9',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.7.10',\n",
       " 'G4',\n",
       " '7.9.11.1.3.4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '9.11',\n",
       " '4.8.11',\n",
       " '3.6',\n",
       " '10.0.3',\n",
       " '4.8.11',\n",
       " '7.10.1',\n",
       " '7.10.1.3',\n",
       " '8.11.2.4.5',\n",
       " '3.6',\n",
       " '3.5.9',\n",
       " '11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '5.8.10',\n",
       " '0.2.4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2',\n",
       " 'E2',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.5.8.10',\n",
       " '4.8.11',\n",
       " '0.2.6',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.5.6.9',\n",
       " '4.8.11',\n",
       " 'G#2',\n",
       " 'F4',\n",
       " 'B-3',\n",
       " '4.8.10.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'D4',\n",
       " '4.8.11',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " '4',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.10',\n",
       " '4.8.11',\n",
       " 'B-0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '11.3.5',\n",
       " 'F4',\n",
       " '7.9.11.1.3.4',\n",
       " '4.8.11',\n",
       " 'F5',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '5.8.11',\n",
       " '4.8.11',\n",
       " 'F4',\n",
       " '1.2.4',\n",
       " '4.8.11',\n",
       " '8.11',\n",
       " '4.8.11',\n",
       " '3.4.8.10',\n",
       " '4.9',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '5.10',\n",
       " '4.8.11',\n",
       " '5.7.10.1',\n",
       " '4.8.11',\n",
       " '2.3.6.9',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " '5.9.11',\n",
       " '6.9.11',\n",
       " 'E-4',\n",
       " '4.9',\n",
       " 'F6',\n",
       " '5.10',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '3.6.8',\n",
       " 'F4',\n",
       " '8.11.1.4',\n",
       " '4.8.11',\n",
       " 'A0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.7.9',\n",
       " '4.8.11',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " '2',\n",
       " '4.8.11',\n",
       " '1.6.7',\n",
       " '11.3',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '9.11.3.4',\n",
       " '5.6',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.8',\n",
       " '5.8',\n",
       " '11.3',\n",
       " '3.6',\n",
       " '5.8.11',\n",
       " '10.1.5',\n",
       " 'F1',\n",
       " 'B2',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.7.8.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '3.5.10',\n",
       " 'A0',\n",
       " '1.2.4',\n",
       " '3.4.5',\n",
       " '2.8',\n",
       " '5.7.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '1.4.7',\n",
       " '4.8.11',\n",
       " 'C#3',\n",
       " '5.8.10.1',\n",
       " '4.8.11',\n",
       " '6.9.10.1',\n",
       " '4.6.9',\n",
       " '3.6.8',\n",
       " '2.5.8.10',\n",
       " 'G2',\n",
       " '4.8.11',\n",
       " 'D4',\n",
       " '5.6',\n",
       " '2.5.8.10',\n",
       " '3.6',\n",
       " '7.10.1.2',\n",
       " '4.8.11',\n",
       " '3.6.7',\n",
       " '4.8.11',\n",
       " '3.6.7',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '0',\n",
       " '10.0.3',\n",
       " '4.8.11',\n",
       " '9.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.8.11',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '4.8.11',\n",
       " '1.3.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '11.3.5',\n",
       " '4.8.11',\n",
       " '5.7.10.1',\n",
       " 'E5',\n",
       " '8.11.1.4',\n",
       " '4.8.11',\n",
       " 'A5',\n",
       " '1.4.7.9',\n",
       " '5.10',\n",
       " '4.8.11',\n",
       " '5.6',\n",
       " '5.8.10.1',\n",
       " '3.7.9.10',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '5.8.10.1',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.11.2.4.5',\n",
       " '4.8.11',\n",
       " '1.3.5.8',\n",
       " '4.8.11',\n",
       " '6.9.11',\n",
       " '11.3',\n",
       " '4.8.11.0',\n",
       " '4.6.8',\n",
       " '4.8.11',\n",
       " '2.3.6.9',\n",
       " '3.6',\n",
       " '6.10.11.0',\n",
       " '10.0.3',\n",
       " '10.11.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'C4',\n",
       " '4.8.11',\n",
       " 'G2',\n",
       " '7.9.11.1.3.4',\n",
       " '4.8.11',\n",
       " '3.7.10',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '2.7.8',\n",
       " 'F4',\n",
       " '4.8.11',\n",
       " 'C#2',\n",
       " '4.8.11',\n",
       " '1.2.4.7.9',\n",
       " '3.6.10',\n",
       " '1.5',\n",
       " '2.3.6.9',\n",
       " '4.8.11',\n",
       " '5.7.9.11.0',\n",
       " '0.4',\n",
       " '9.11',\n",
       " '4.8.11',\n",
       " '5.7.10.0',\n",
       " '5.6.11',\n",
       " '10.0.3',\n",
       " '4.8.11',\n",
       " '9.0',\n",
       " '11.4.5',\n",
       " 'F4',\n",
       " '4.7.8.11',\n",
       " '4.8.11',\n",
       " '1.2.4.7.9',\n",
       " '4.8.11',\n",
       " '2.5.8.10',\n",
       " '5.7.11.0',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '8.10',\n",
       " '4.8.11',\n",
       " '9.11.0.4',\n",
       " '4.8.11',\n",
       " 'C#5',\n",
       " '1.3.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '6.10.11.0',\n",
       " '5.6.11',\n",
       " '4.8.11',\n",
       " '1.3.8',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '11.3',\n",
       " '9.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " '4.8.11',\n",
       " 'F#6',\n",
       " '10.0.1.5',\n",
       " '9.11']"
      ]
     },
     "execution_count": 1120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_output.mid'"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from music21 import stream\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 519])"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.05394990366088632],\n",
       " [0.8998073217726397],\n",
       " [0.8978805394990366],\n",
       " [0.7687861271676301],\n",
       " [0.9402697495183044],\n",
       " [0.953757225433526],\n",
       " [0.8420038535645472],\n",
       " [0.8689788053949904],\n",
       " [0.9402697495183044],\n",
       " [0.9267822736030829],\n",
       " [0.8689788053949904],\n",
       " [0.8053949903660886],\n",
       " [0.33911368015414256],\n",
       " [0.19460500963391136],\n",
       " [0.8053949903660886],\n",
       " [0.6454720616570327],\n",
       " [0.9383429672447013],\n",
       " [0.9364161849710982],\n",
       " [0.605009633911368],\n",
       " [0.8400770712909441],\n",
       " [0.6454720616570327],\n",
       " [0.9017341040462428],\n",
       " [0.8420038535645472],\n",
       " [0.8998073217726397],\n",
       " [0.8362235067437379],\n",
       " [0.838150289017341],\n",
       " [0.6454720616570327],\n",
       " [0.605009633911368],\n",
       " [0.441233140655106],\n",
       " [0.8670520231213873],\n",
       " [0.8651252408477842],\n",
       " [0.9903660886319846],\n",
       " [0.953757225433526],\n",
       " [0.9267822736030829],\n",
       " [0.9518304431599229],\n",
       " [0.7687861271676301],\n",
       " [0.9402697495183044],\n",
       " [0.8574181117533719],\n",
       " [0.884393063583815],\n",
       " [0.011560693641618497],\n",
       " [0.8420038535645472],\n",
       " [0.33911368015414256],\n",
       " [0.8053949903660886],\n",
       " [0.8053949903660886],\n",
       " [0.8689788053949904],\n",
       " [0.6454720616570327],\n",
       " [0.9383429672447013],\n",
       " [0.9364161849710982],\n",
       " [0.605009633911368],\n",
       " [0.8400770712909441],\n",
       " [0.9922928709055877],\n",
       " [0.8689788053949904],\n",
       " [0.8709055876685935],\n",
       " [0.8362235067437379],\n",
       " [0.838150289017341],\n",
       " [0.7687861271676301],\n",
       " [0.8998073217726397],\n",
       " [0.6454720616570327],\n",
       " [0.8689788053949904],\n",
       " [0.605009633911368],\n",
       " [0.8400770712909441],\n",
       " [0.4007707129094412],\n",
       " [0.9922928709055877],\n",
       " [0.19460500963391136],\n",
       " [0.3699421965317919],\n",
       " [0.8863198458574181],\n",
       " [0.24470134874759153],\n",
       " [0.5626204238921002],\n",
       " [0.8863198458574181],\n",
       " [0.5626204238921002],\n",
       " [0.9267822736030829],\n",
       " [0.8863198458574181],\n",
       " [0.953757225433526],\n",
       " [0.9267822736030829],\n",
       " [0.8689788053949904],\n",
       " [0.8709055876685935],\n",
       " [0.9402697495183044],\n",
       " [0.9807321772639692],\n",
       " [0.953757225433526],\n",
       " [0.8420038535645472],\n",
       " [0.8709055876685935],\n",
       " [0.9807321772639692],\n",
       " [0.953757225433526],\n",
       " [0.8420038535645472],\n",
       " [0.9807321772639692],\n",
       " [0.9672447013487476],\n",
       " [0.953757225433526],\n",
       " [0.8420038535645472],\n",
       " [0.9402697495183044],\n",
       " [0.8863198458574181],\n",
       " [0.8709055876685935],\n",
       " [0.3988439306358382],\n",
       " [0.19460500963391136],\n",
       " [0.8863198458574181],\n",
       " [0.9402697495183044],\n",
       " [0.8246628131021194],\n",
       " [0.7283236994219653],\n",
       " [0.2543352601156069],\n",
       " [0.7283236994219653],\n",
       " [0.2543352601156069]]"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
